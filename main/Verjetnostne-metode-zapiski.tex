\documentclass[a4paper, 12pt]{book}

\usepackage{fancyhdr}

\newcommand{\ttitle}{Verjetnostne metode v računalništvu - zapiski s predavanj prof. Marca}
\newcommand{\ttitleshort}{Verjetnostne metode v računalništvu}
\newcommand{\tauthor}{Tomaž Poljanšek}
\newcommand{\tdate}{študijsko leto 2023/24}

\usepackage{color}
\usepackage{soul}
\usepackage[numbers]{natbib}

\usepackage{physics}

\usepackage[parfill]{parskip}
\usepackage[hyphens]{url}

\usepackage[usestackEOL]{stackengine}[2013-10-15] % formatting Pascal
\usepackage[dvipsnames]{xcolor}

\usepackage{cancel}
\usepackage[export]{adjustbox}

% Related to math
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{mathtools}
\usepackage{youngtab}
\usepackage{tikz}

% encoding and language
\usepackage{lmodern}
\usepackage[slovene, english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

% multiline comments
\usepackage{comment}
\usepackage{verbatim}

% random text - for texting
\usepackage{lipsum}
\usepackage{blindtext}

\usepackage{hyperref}

% images
\usepackage{graphicx}
\graphicspath{ {../images/} }

% no blank page
\usepackage{atbegshi}
\renewcommand{\cleardoublepage}{\clearpage}
%\renewcommand{\clearpage}{}

\usepackage{listings}
\usepackage{verbatim}
%\usepackage{fancyvrb}
%\usepackage{bera}

\newcommand*\Eval[3]{\left.#1\right\rvert_{#2}^{#3}}

\lstset{basicstyle=\ttfamily,
escapeinside={||},
mathescape=true}

% theorems
\theoremstyle{definition}
\newtheorem{counter}{Counter}[section]
\newtheorem{defn}[counter]{Definicija}
\newtheorem{lemma}[counter]{Lema}
\newtheorem{conseq}[counter]{Posledica}
\newtheorem{claim}[counter]{Trditev}
\newtheorem{theorem}[counter]{Izrek}
\newtheorem{pro}[counter]{Dokaz}
%%
\theoremstyle{remark}
\newtheorem*{ex}{Primer}
\newtheorem*{exmp}{Zgled}
\newtheorem*{rem}{Opomba}

% QED
\renewcommand\qedsymbol{$\blacksquare$}

\hypersetup{pdftitle={\ttitle}}

\addtolength{\marginparwidth}{-20pt}
\addtolength{\oddsidemargin}{40pt}
\addtolength{\evensidemargin}{-40pt}

\renewcommand{\baselinestretch}{1.3}
\setlength{\headheight}{15pt}
\renewcommand{\chaptermark}[1]
{\markboth{\MakeUppercase{\thechapter.\ #1}}{}} \renewcommand{\sectionmark}[1]
{\markright{\MakeUppercase{\thesection.\ #1}}} \renewcommand{\headrulewidth}{0.5pt} \renewcommand{\footrulewidth}{0pt}

% header
\fancyhf{}
\fancyhead[LE,RO]{\sl \thepage} 
\fancyhead[RE]{\sc \tauthor}
\fancyhead[LO]{\sc \ttitleshort}


\newcommand{\autfont}{\Large}
\newcommand{\titfont}{\LARGE\bf}
\newcommand{\clearemptydoublepage}{\newpage{\pagestyle{empty}\cleardoublepage}}
\setcounter{tocdepth}{1}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\ch}{\operatorname{char}}

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\usepackage{float}
\usepackage{multirow}
\usepackage{icomma}
\usepackage{tabularx}
\usepackage{hhline}

\usepackage{enumitem}
\usepackage{ulem}
\newcommand{\msout}[1]{\text{\sout{\ensuremath{#1}}}} % cross text in math mode

\usepackage{alltt}

\title{\ttitle}
\author{\tauthor}
\date{\tdate}

\newcommand\mymaketitle{
  \begin{titlepage}
    \begin{center}
        \vspace*{4cm}
        \Huge
        \textbf{\ttitle}
                        
        \vspace{1.5cm}
        \huge
        \tauthor
            
        \vspace{3cm}
        \Large
        \tdate
    \end{center}
  \end{titlepage}
}




\begin{document}

\selectlanguage{slovene}
%\setcounter{page}{1}
\renewcommand{\thepage}{}
\newcommand{\sn}[1]{"`#1"'}

\mymaketitle

\clearpage
%\AtBeginShipoutNext{\AtBeginShipoutDiscard}

\frontmatter

% kazalo
\pagestyle{empty}
\def\thepage{}
\tableofcontents{}

%%
\def\x{\hspace{3ex}}    %BETWEEN TWO 1-DIGIT NUMBERS
\def\y{\hspace{2.45ex}}  %BETWEEN 1 AND 2 DIGIT NUMBERS
\def\z{\hspace{1.9ex}}    %BETWEEN TWO 2-DIGIT NUMBERS
\stackMath

%\clearpage
%\phantomsection
%\addcontentsline{toc}{chapter}{Povzetek}
%\chapter*{Povzetek}

%Predloga.

%\newpage

\pagenumbering{arabic}

\mainmatter
\setcounter{page}{1}
\pagestyle{fancy}


% 1. predavanje: 6.10.


\chapter{Introduction}


\section{Probability}

$(\Omega, F, P_r)$:
\begin{itemize}[label=$\circ$]
  \item $\emptyset \in F$,
  \item $A \in F \implies A^c \in F$,
  \item $A_1, A_2 \dots \in F \implies \cup_{i=1}^{\infty} A_i \in F$.
\end{itemize}
$P_r(A) \geq 0$, \\
$P_r\left(\cup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P_r(A_i)$ if $A_i$ disjoint, \\
$P_r\left(\cup_{i=1}^{\infty} A_i\right) \leq \sum_{i=1}^{\infty} P_r(A_i)$, \\
$\Omega = \{\omega_1, \omega_2 \dots\}$ - countable case. \\
$\begin{pmatrix}
  \omega_1 & \omega_2 & \dots \\
  p_1 & p_2 & \dots
\end{pmatrix}$
\begin{ex} \text{}
  \begin{verbatim}
    Alg():
      while True:
        B = sample as random from {0,1}  # 1 with probability p
        if B = 1:
          return
  \end{verbatim}
  $\Omega = \{1, 01, 001, 0001 \dots\}$ \\
  $\begin{pmatrix}
    1 & 01 & 001 & 0001 & \dots \\
    p & (1-p)p & (1-p)^2 p & (1-p)^3p & \dots
  \end{pmatrix}$.
\end{ex}


\section{Random variables}

$X: \Omega \to \Z$. \\
$E[X] = \sum_{c \in \Z} c \cdot P_r(X = c)$ expected value of $X$. \\
Properties:
\begin{itemize}[label=$\circ$]
  \item $E[f(X)] = \sum_{c \in \Z} f(c) \cdot P_r(X = c)$,
  \item $E[aX + bY] = aE[X] + bE[Y]$,
  \item $E[X \cdot Y] = E[X] \cdot E[Y]$ if $X, Y$ independent,
  \item $P_r(X \geq a) \leq \frac{E[X]}{a} \; \forall a > 0 \; X \geq 0$ Markov inequality.
\end{itemize}
\begin{ex}
  (Continuing from before). \\
  $X =$ number of trials before return. \\
  $X: \Omega \to \Z$. \\
  $X: 1 \to 1, 01 \to 2, 003 \to 3 \dots$ \\
  $\begin{pmatrix}
    1 & 2 & 3 & 4 & \dots \\
    p & (1-p)p & (1-p)^2 p & (1-p)^3p & \dots
  \end{pmatrix}$ - geometric distribution.
\end{ex}
\begin{claim}
  $E[X] = \frac{1}{p}$.
\end{claim}
\begin{pro}
  $X = \sum_{i=1}^{\infty} X_i$. \\
  $X_i = \begin{cases}
    1 \text{ if trial $i$ is executed} \\
    0 \text{ else}
  \end{cases}$ \\
  \begin{align*}
    E[X] &= E[\sum_{i=1}^{\infty} X_i] = \sum_{i=1}^{\infty} E[X_i] = \\
    &= \sum_{i=1}^{\infty} (1-p)^{i-1} = \frac{i=0}{\infty} (1-p)^i = \frac{1}{1-(1-p)} = \frac{1}{p}.
  \end{align*}
\end{pro}
$E[X] = \frac{1}{p}$. \\
$P_r(X \geq 100 \cdot \frac{1}{p}) \leq \frac{E[X]}{\frac{1}{p}} = \frac{1}{100}$.
\begin{defn}
  $H_n = 1 + \frac{1}{2} + \frac{1}{3} + \dots + \frac{1}{n} = \sum_{i=1}^{\infty} \frac{1}{i}$.
\end{defn}
\begin{theorem}
  $H_n \leq 1 + \ln(n)$.
\end{theorem}
\begin{pro}
  \begin{equation*}
    H_n = 1 + \sum_{i=2}^{n} \frac{1}{i} \stackrel{\text{integral}}{\leq}
    1 + \int_{1}^{n} \frac{dx}{x} = 1 + \Eval{\ln(x)}{1}{n} = 1 + \ln(n).
  \end{equation*}
  % skica
\end{pro}



\chapter{Quicksort, min-cut}


\section{Quicksort}

\begin{alltt}
  Input: set (no equal element) (unordered list) S\(\in\R\)
      (or whatever you can compare linearly)
  Output: ordered list
  Code:
    def Quicksort(S):
      if |S|= 0 or 1:
        return S
      else:
        a = uniformly at random from S
        S\(\sp{-}\) = \{b \(\in\) S | b < a\}
        S\(\sp{+}\) = \{b \(\in\) S | a < b\}
        return Quicksort(S\(\sp{-}\)), a, Quicksort(S\(\sp{+}\))
\end{alltt}
% skica
$C(n)$ - random variable, the number of comparisons in evaluation of Quicksort with $|S| = n$.
\begin{theorem}
  $E[C(n)] = O\left(N \log(n)\right)$.
\end{theorem}
\begin{pro}
  $C(0) = C(1) = 0$. \\
  \begin{align*}
    E[C(n)] &= n - 1 + \sum_{i=1}^{n} \left(E[C(i-1)] + E[C(n-i)]\right) \cdot P_r(a \text{ is $i$-it element}) \leq \\
    &\leq n + \frac{2}{n} \sum_{i=1}^{n-1} E[C(i)].
  \end{align*}
  Induction: \\
  $n = 1: \checkmark$ \\
  $n-1 \to n$:
  \begin{align*}
    E[C(n)] &\leq n + \frac{2}{n} \sum_{i=1}^{n} E[C(i)] \leq \\
    &\leq n + \frac{2}{n} \sum_{i=1}^{n} 5i \log i \leq \\
    &\leq n + \frac{2}{n} \sum_{i=1}^{\lfloor\frac{n}{2}\rfloor} 5i \log i +
      \frac{2}{n} \sum_{i=1+\lfloor\frac{n}{2}\rfloor}^{n-1} 5i \log i \leq \\
    &\leq n + \frac{2}{n} \sum_{i=1}^{\lfloor\frac{n}{2}\rfloor} 5i \log \frac{n}{2} +
      \frac{2}{n} \sum_{i=1+\lfloor\frac{n}{2}\rfloor}^{n-1} 5i \log n \leq \\
    (\log \frac{n}{2} &= \log n - 1) \\
    &\leq n + \frac{2}{n} \left(\sum_{i=1}^n 5i \log n - \sum_{i=1}^{\frac{n}{2}} 5i\right) = \\
    &= n + \frac{10}{n} \left(\frac{n(n-1)}{2} \log n - \frac{\frac{n}{2} (\frac{n}{2} + 1)}{2}\right) \leq \\
    &\leq n + 5(n-1) \log n - n < \\
    &< 5n \log n.
  \end{align*}
\end{pro}
$P\left(C(n) \geq b \cdot 5n \log n\right) \stackrel{\text{Markov}}{\leq} \frac{1}{b}$.
\begin{pro} \text{} \\
  2: \\
  Let $S_1, S_2 \dots S_n$ sorted elements of $S$. \\
  Define random variable
  $X_{ij} = \begin{cases}
    1 \text{ if $S_i$ and $S_j$ are compared} \\
    0 \text{ else}
  \end{cases}$ \\
  $C(n) = \sum_{1 \leq i < j \leq n} E[X_{ij}]$. \\
  $E[X_{ij}] = P(S_i$ and $X_j$ compared$)$. \\
  % skica
  $S_{ij}$ - the last set including $S_i$ and $S_j$. \\
  $E[X_{ij}] = \frac{2}{|S_{ij}|} \leq \frac{2}{j-i+1}$. \\
  $|S_{ij}| \geq j - i + 1$. \\
  $S_{ij}$ has everything in between. \\
  \begin{align*}
    \implies E[C(n)] &\leq \sum_{1 \leq i < j \leq n} \frac{2}{j-i+1} = \\
    &\stackrel{k=j-i+1}{=} \sum_{i=1}^{n-1} \sum_{k=2}^{n-i+1} \frac{2}{k} \leq \\
    &\leq 2 \cdot n \cdot H_n \leq \\
    &\leq 2 n (1 + \log n).
  \end{align*}
\end{pro}


% 2. predavanje: 13.10.

\section{Min-cut}

$G$ multigraph. \\
Cut: $U \subset V(G), \; U \neq \emptyset, V(g)$. \\
$(U, V(G) \setminus U) = \{uv \in E(G) \mid u \in U, v \in V(G) \setminus U\}$. \\
% skica
Problem min-cut: \\
Input: $G$. \\
Output: $\min |(U, V(G) \setminus U)|$ - cut size.
\begin{alltt}
  Algorithm 1:
    x \(\in\) V(G)
    Call maxFlow(G, x, y) \(\forall y \in V(G)\)
    Take min
\end{alltt}
$maxFlow$ is Edmonds-Karp algorithm $O\left(|V| |E|^2\right)$. \\
\begin{alltt}
  Algorithm 2 (Stoer Wagner)
\end{alltt}
Is $O\left(|E| |V| + |V| log |V|\right)$.
\begin{alltt}
  Algorithm randMinCut:
    G\(\sb_{0}\) = G
    i = 0
    while |V(G\(\sb{i}\))| > 2:
      e\(\sb{i}\) = uniformly at random from G\(\sb{i}\)
      G\(\sb{i+1}\) = G\(\sb{i}\) / \(\sb{e\sb{i}}\)
      i = i + 1
    u, v = V(G\(\sb{n-2}\)) // n = |V(G)|
    U = \{w \(\in\) V(G) | w is merged into u\}
    return (U, V(G) \textbackslash U)
\end{alltt}
\begin{theorem}
  Algorithm $randMinCut$ gives you a minimal cut with probability greater or equal to $\frac{2}{n(n-1)}$.
\end{theorem}
\begin{pro} \text{} \\
  Fact 1: $minCut(G_i) \leq minCut(G_i)$;
  \begin{itemize}[label={}]
    %\item $\leq$: %example
    \item $\ngtr$: $minCut$ remains.
  \end{itemize}
  Fact 2: $minCut(G) \leq \delta(G)$. \\
  $k := minCut(G)$. \\
  Let $(A,B)$ be an optimal cut. \\
  $\epsilon_i$ not in $(A,B)$.
  \begin{align}
    &P_r(\text{Algorithm not returning } (A,B)) \nonumber \\
    &= P_r(\epsilon_0 \cap \dots \cap \epsilon_{n-3}) \nonumber  \\
    &= P_r(\epsilon_0 \cap \dots \cap \epsilon_{n-4}) \cdot
      P_r(\epsilon_{n-3} \mid \epsilon_0 \cap \dots \cap \epsilon_{n-4}) \nonumber  \\
    &= P_r(\epsilon_{n-3} \mid \cap_{i=0}^{n-4} \epsilon_i) \cdot
      P_r(\epsilon_{n-3} \mid \cap_{i=0}^{n-4} \epsilon_i) \nonumber \\
    &\dots P_r(\epsilon_1 \mid \epsilon_0) \cdot P_r(\epsilon_0). (*) %\label{randMinCut-mid}
  \end{align}
  \begin{equation*}
    P_r(\overline{\epsilon_i} \mid \epsilon_{i-1} \cap \dots \cap \epsilon_0) =
      %\frac{k}{|E(G_i)|} \stackrel{\text{\refeq{E-gi}}}{\leq} \frac{k}{\frac{(n-i)k}{2}} = \frac{2}{n-i}
      \frac{k}{|E(G_i)|} \stackrel{\text{(**)}}{\leq} \frac{k}{\frac{(n-i)k}{2}} = \frac{2}{n-i}
  \end{equation*}
  \begin{equation}
    |E(G_i)| \geq \frac{(n-i) \delta(G)}{2} \geq \frac{(n-i)k}{2}. (**) % \label(E-gi)
  \end{equation}
  \begin{equation*}
    P_r(\epsilon_i \mid \epsilon_{i-1} \cap \dots \cap \epsilon_0) \geq 1 - \frac{2}{n-i} = \frac{n-2-i}{n-i}.
  \end{equation*}
  \begin{equation*}
    %\text{\ref{randMinCut-mid}} \geq \frac{n-2}{n} \cdot \frac{n-3}{n-1} \dots \frac{1}{3} = \frac{2}{n(n-1)}.
    (*) \geq \frac{n-2}{n} \cdot \frac{n-3}{n-1} \dots \frac{1}{3} = \frac{2}{n(n-1)}.
  \end{equation*}
\end{pro}
\begin{theorem}
  Running $randMinCut \; n(n-1)$ times and taking best output gives correct solution with probability $\geq 0.86$.
\end{theorem}
\begin{pro}
  $A_i$ - event that $i$-th run gives sub-optimal solution.
  \begin{align*}
    P_r(\text{solution not correct}) &= P_r(A_1 \cap \dots \cap A_{n(n-1)}) \\
    &= \prod_{i=1}^{n(n-1)} P_r(A_i) \leq (1 - \frac{2}{n(n-1)})^{n(n-1)} \\
    &\leq e^{-\frac{2}{n(n-1)} \cdot n(n-1)} = e^{-2} \leq 0.14.
  \end{align*}
  $1 - x \leq e^x \; \forall x \in \R$.
\end{pro}
If we run $n(n-1) log(n)$ times $\to O\left(\frac{1}{n}\right)$. \\
$O\left(n^2 \log n \cdot n\right)$. \\
Improved: $O\left(n^2 \log^3 n\right)$.



\chapter{Complexity classes}


Decision problem - yes/no question on a set of inputs = asking $w \in \Pi$. \\
Randomized algorithms:
\begin{itemize}
  \item Las Vegas algorithms: always gives correct solution, example: $Quicksort$.
  \item Monte Carlo algorithms: it can give wrong answers.
    Monte Carlo algorithms subtypes:
    \begin{itemize}
      \item type(1): $\begin{cases}
          \text{if } \omega \in \Pi \implies \text{ algorithm returns \sn{$\omega \in \Pi$} with probability } \geq \frac{1}{2} \\ 
          \text{if } \omega \notin \Pi \implies \text{ algorithm returns \sn{$\omega \in \Pi$} with probability } = 0 
        \end{cases}$
      \item type(2): $\begin{cases}
          \text{if } \omega \in \Pi \implies \text{ algorithm returns \sn{$\omega \in \Pi$} with probability } = 1 \\ 
          \text{if } \omega \notin \Pi \implies \text{ algorithm returns \sn{$\omega \in \Pi$} with probability } \leq \frac{1}{2} 
        \end{cases}$
      \item type(3): $\begin{cases}
          \text{if } \omega \in \Pi \implies \text{ algorithm returns \sn{$\omega \in \Pi$} with probability } \geq \frac{3}{4} \\ 
          \text{if } \omega \notin \Pi \implies \text{ algorithm returns \sn{$\omega \in \Pi$} with probability } \leq \frac{1}{2}
        \end{cases}$
    \end{itemize}
    type(1) and type(2): one-sided error, type(3): 2-sided error. \\
    $\frac{1}{2}, \frac{3}{4}$ and $\frac{1}{4}$ arbitrary numbers, can be something different (for type(3) better than coin flip).
\end{itemize}
\begin{ex}
  Decisional problem: does a graph $G$ have $minCut \leq k$? \\
  Run $randMinCut(G) \; n(n-1)$ times.
  \begin{alltt}
    Algorithm randMinCut:
      if one of runs gives |(A,B)| \(\leq\) k:
        return true
      else:
        return false
  \end{alltt}
\end{ex}
Complexity classes:
\begin{itemize}
  \item RP (randomized polynomial time): decisional problems for which there exists Monte Carlo algorithm of type(1)
    with polynomial time complexity (worst case).
  \item co-RP: decisional problems for which there exists Monte Carlo algorithm of type(2) with polynomial time complexity
    (worst case).
  \item BRP (bounded-error probabilistic polynomial time): decisional problems for which there exists Monte Carlo algorithm of type(3)
    with polynomial time complexity (worst case).
  \item ZPP (zero-error probabilistic polynomial time): decisional problems for which there exists Las Vegas algorithm
    with expected polynomial time complexity (worst case).
\end{itemize}
% skica
ZPP = RP $\cap$ co-RP.



\chapter{Chernoff bounds}


\begin{theorem}
  Let $X_1, X_2 \dots X_n$ independent random variables with image $\{0, 1\}$. \\
  Let $p_i = P_r(X_i = x_i), X = \sum_{i=1}^{n} X_i$ and $\mu = E(X) = p_1 + \dots + p_n$. \\
  For every $\delta \in (0,1)$:
  \begin{align*}
    &P_r(X - \mu \geq \delta \mu) \leq e^{-\frac{\delta^2 \mu}{3}} \\
    &P_r(\mu - X \leq \delta \mu) \leq e^{-\frac{\delta^2 \mu}{2}} \\
    \implies &P_r(|X - \mu| \geq \delta \mu) \leq e^{-\frac{\delta^2 \mu}{3}}. \\
  \end{align*}
\end{theorem}
% skica
Probability falls extremely quickly after $E(X)$.


% 3. predavanje: 20.10.

\begin{pro}
  \begin{align*}
    P_r(X - \mu \geq \delta \mu) &= P_r(X \geq \mu(1+\delta)) \\
    &\stackrel{t>0}{=} P_r(tX \geq t\mu(1+\delta)) \\
    &\stackrel{e^y>0}{=} P_r(e^{tX} \geq e^{t\mu(1+\delta)}) \\
    &\stackrel{\text{Markov}}{\leq} \frac{E\left(e^{tX}\right)}{e^{t\mu(1+\delta)}} \\
    &\stackrel{\refeq{eq:et_x}}{\leq} \frac{e^{(e^t-1)\mu}}{e^{t\mu(1+\delta)}} \\
    &\stackrel{\refeq{eq:leq_in_exp}}{\leq} e^{-\mu \frac{\delta^2}{3}}.
  \end{align*}
  \begin{align}
    E(e^{tX}) &= E(e^{tX_1 + \dots + tX_n}) \nonumber \\
    &= E(e^{tX_1} \dots e^{tX_n}) \nonumber \\
    &\stackrel{\text{independent}}{=} \prod_{i=1}^{n} E(e^{tX_i}) \nonumber \\
    &\stackrel{\refeq{eq:et_xi}}{\leq} \prod_{i=1}^{n} e^{p_i(e^t-1)} \nonumber \\
    &= e^{(e^t-1) \sum_{i=1}^{n}p_i} \nonumber \\
    &= e^{(e^t-1)\mu} \label{eq:et_x}.
  \end{align}
  \begin{equation}
    E(e^{tX_i}) = p_i \cdot e^t + (1-p_i) \cdot e^0 = 1+p_i(e^t-1) \stackrel{1+x\leq e^x}{\leq} e^{p_i(e^t-1)}.
    \label{eq:et_xi}
  \end{equation}
  Want:
  \begin{equation}
    e^t - 1 - t(1+\delta) \leq -\frac{\delta^2}{3} \; \forall \delta \in (0,1) \label{eq:leq_in_exp}
  \end{equation}
  \begin{align*}
    &t = \ln(1+\delta) \\
    &f(\delta) = 1 + \delta - 1 - (1+\delta) \ln(1+\delta) + \frac{\delta^2}{3} \stackrel{?}{\leq} 0 \\
    &f(0) = 0 \\
    &f^{'}(\delta) = 1 - \ln(1+\delta) - 1 + \frac{2}{3} \delta = \frac{2}{3} \delta - \ln(1+\delta) \stackrel{?}{\leq} 0 \\
    &\frac{2}{3} \delta \leq \ln(1+\delta) \\
    % skica
    &\delta=1: \; \frac{2}{3} \stackrel{?}{\leq} \ln(2) \approx 0.69 \checkmark
  \end{align*}
  \begin{align*}
    P_r(\mu - X \leq \delta \mu) &= P_r(X \geq \mu(1-\delta)) \\
    &\stackrel{t>0}{=} P_r(tX \geq t\mu(1-\delta)) \\
    &\stackrel{e^y>0}{=} P_r(e^{tX} \geq e^{t\mu(1-\delta)}) \\
    &\leq \dots \leq \frac{e^{(e^t-1)\mu}}{e^{t\mu(1-\delta)}}.
  \end{align*}
  Want: $e^t - 1 - t(1-\delta) \leq -\frac{\delta^2}{2} \; \forall \delta \in (0,1)$:
  \begin{align*}
    &t = \ln(1-\delta) \\
    &f(\delta) = 1 - \delta - 1 - (1-\delta) \ln(1-\delta) + \frac{\delta^2}{2} \stackrel{?}{\leq} 0 \\
    &f(0) = 0 \\
    &f^{'}(\delta) = - 1 + 1 - \ln(1-\delta) + \delta \stackrel{?}{\leq} 0 \\
    &\frac{2}{3} \delta \leq \ln(1+\delta) \\
    &\ln(1-\delta) \stackrel{?}{\leq} -\delta \checkmark
    % skica
  \end{align*}
  \qed
\end{pro}
$X_i \sim \begin{pmatrix}0 & 1 \\ \frac{1}{2} & \frac{1}{2}\end{pmatrix}$ \\
$X = \sum_{i=1}^{n} X_i$ \\
$\mu = \frac{n}{2}$
\begin{align*}
  P_r(|X-\mu| \geq \sqrt{\frac{3}{2}n \ln(n)}) &= P_r(|X-\mu| \geq \frac{n}{2} \sqrt{\frac{6}{n} \ln(n)}) \\
  &\quad \mu = \frac{n}{2}, \delta = \sqrt{\frac{6}{n} \ln(n)}, \\
  &\quad \text{for \sn{big} }n \delta \in (0,1) \\
  &\stackrel{\text{Chernoff}}{\leq} 2 e^{-\frac{\frac{n}{2} \frac{6}{n} \ln(n)}{3}} = \frac{2}{n}.
\end{align*}
$d = \sqrt{\frac{3}{2}n \ln(n)}$
% skica
\begin{equation*}
  \implies P_r(X \in (\mu - \sqrt{\frac{3}{2}n \ln(n)}, \mu + \sqrt{\frac{3}{2}n \ln(n)})) \geq 1 - \frac{2}{n}.
\end{equation*}
% skica
\begin{claim} \text{} \\
  Let $X_1, X_2 \dots$ independent random variables with image $\{0,1\}$. \\
  $P_r(X_i = 1) = \frac{1}{2} \; \forall i$. \\
  Let $X = \sum_{i=1}^{cm} X_i$ where $c \geq 4$. \\
  Then $P_r(X \leq m) \leq e^{-\frac{cm}{16}}$.
\end{claim}
\begin{pro}
  \begin{align*}
    P_r(X \leq m) &= P_r(\frac{cm}{2} - X \geq \frac{cm}{2} - m) \\
    &= P_r(\frac{cm}{2} - X \geq \frac{cm}{2} (1 - \frac{2}{c})) \\
    &\stackrel{\text{Chernoff}}{\leq} e^{-\frac{\frac{cm}{2} (1-\frac{2}{c})^2}{2}} \\
    &\quad 1-\frac{2}{c} \geq \frac{1}{2} \text{ if } c \geq 4 \\
    &\leq e^{-\frac{\frac{cm}{2} \frac{1}{4}}{2}} = e^{-\frac{cm}{16}}.
  \end{align*}
  \qed
\end{pro}
Back to Quicksort.
\begin{theorem} \text{} \\
  With probability $\geq 1 - \frac{1}{n}$ Quicksort uses at most $48n\ln(n)$ comparisons.
\end{theorem}
\begin{pro} \text{} \\
  % skica (i)
  For $s \in S$ define $S_1^S \dots S_{t_s}^S \neq \emptyset$ sets that include $s$,
  $t_s$ - number of comparisons with $s$ where $s$ is not a pivot $+1$. \\
  Define: iteration $i$ is successful if $|S_{i+1}| \leq \frac{3}{4} |S_i|$ ($\frac{1}{2}$ is too strict).
  \begin{equation*}
    X_i = \begin{cases}
      1 \text{ if iteration } i \text{ is successful} \\
      0 \text{ else}
    \end{cases}
  \end{equation*}
  % skica (i)
  $P_r(X_i = 1) \geq \frac{1}{2}$ \\
  $S_i: n \to \frac{3}{4} n \to (\frac{3}{4})^2 n \to \dots \to 1$. \\
  Notice: max number of iteration is $\log_{\frac{4}{3}}(n) = \frac{\ln(n)}{\ln(4)-\ln(3)}$. \\
  Probability that we haven't succeeded in $\log_{\frac{4}{3}}(n)$ steps:
  \begin{align}
    P_r(\sum_{i=1}^{c \log_{\frac{4}{3}}(n)} X_i < \log_{\frac{4}{3}}(n)) &\leq
      P_r(\sum_{i=1}^{c \log_{\frac{4}{3}}(n)} Y_i < \log_{\frac{4}{3}}(n)) \label{eq:X_to_Y} \\
    &\stackrel{\text{Chernoff}}{<} e^{-\frac{c \log_{\frac{4}{3}}(n)}{24}} \\
    &= e^{-\frac{c \ln(n) \log_{\frac{4}{3}}(e)}{24}} \\
    &= \frac{1}{n} \frac{c \log_{\frac{4}{3}}(e)}{24} \\
    &\quad \log_{\frac{4}{3}}(e) \approx 3.4, \; c=14 \\
    &\leq \left(\frac{1}{n}\right)^2
  \end{align}
  \refeq{eq:X_to_Y} because $X_i$ not independent,
  $Y_i \sim \begin{pmatrix}0 & 1 \\ \frac{1}{2} & \frac{1}{2}\end{pmatrix}$ independent. \\
  $P_r(t_s \geq c \log_{\frac{4}{3}}(n)) \geq \left(\frac{1}{n}\right)^2$ for one $s$. \\
  $c=14 \implies$ at least $48 \ln(n)$ iterations with probability $\leq \left(\frac{1}{n}\right)^2$. \\
  With probability as least $1-\frac{1}{n}$ for all $s \in S$ it holds that $s$ has $\leq 48 \ln(n)$ comparisons with a pivot. \\
  $\implies$ total number of comparisons $n \cdot 48 \ln(n)$ with probability as least $1 - \frac{1}{n}$.
  \qed
\end{pro}



\chapter{Monte Carlo methods}


\section{Example 1}

% skica
Area of circle $= \frac{\pi}{4}$. \\
$X_i = \begin{cases}
  1 \text{ if you hit the area of circle} \\
  0 \text{ else}
\end{cases}$ \\
$P_r(X_i = 1) = \frac{\frac{\pi}{2}}{1} = \frac{\pi}{4}$. \\
$E(X_i) = \frac{\pi}{4}$. \\
$X = \frac{\sum_{i=1}^{n} X_i}{n}$. \\
$E(X) = \frac{n \cdot E(X_i)}{n} = E(X_i)$.


% 4. predavanje: 27.10.

\section{Example 2}

$I = \int_{\Omega} f(x) dx$ - volume. \\
% skica
$X_i = \begin{cases}
  1 \; F(x_i,y_i) \leq z_i \\
  0 \text{ otherwise}
\end{cases}$ \\
$v \cdot E\left(\frac{\sum_{i=1}^{n} X_i}{n}\right) = I$.


\section{$(\epsilon,\delta)$-approximation}

\begin{defn}[$(\epsilon,\delta)$-approximation]
  A random algorithm gives a $(\epsilon,\delta)$-approximation for value $v$ if the output $X$ satisfies:
  \begin{equation*}
    P_r(|X-v| \leq \epsilon v) \geq 1 - \delta.
  \end{equation*}
\end{defn}
\begin{theorem}
  Let $X_1 \dots X_n$ be independent and identically distributed indicator variables.
  Let $\mu = E(X_i), \; Y = \frac{\sum_{i=1}^{m} X_i}{m}$.
  If $m \geq \frac{3 \ln\left(\frac{2}{\delta}\right)}{\epsilon^2 \mu}$, then $P_r(|Y-\mu| \geq \epsilon \mu) \leq \delta$
  $\implies Y$ is $(\epsilon,\delta)$-approximation for $\mu$.
\end{theorem}
\begin{pro} \text{} \\
  $X = \sum_{i=1}^{n} X_i$ \\
  $E(X) = m E(x_i) = m \mu$ \\
  $m \geq \frac{3 \ln\left(\frac{2}{\delta}\right)}{\epsilon^2 \mu}$
  \begin{align*}
    P_r(|Y-\mu| \geq \epsilon \mu) &= P_r(\left|\frac{X}{m}-\mu\right| \geq \epsilon \mu) \\
    &= P_r(\frac{1}{m} \left|X-E(X)\right| \geq \frac{1}{m} \epsilon E(x)) \\
    &\stackrel{\text{Chernoff}}{\leq} 2 e^{-\frac{\epsilon^2 E(x)}{3}} \\
    &= 2 e^{-\frac{\epsilon^2 \mu m}{3}} \\
    &\leq 2 e^{-\frac{\epsilon^2 \mu}{3} \cdot \frac{3 \ln\left(\frac{2}{\delta}\right)}{\epsilon^2 \mu}} = \delta.
  \end{align*}
\end{pro}
Back to example 1: \\
$E(Y) = \frac{\pi}{4}, \delta = \frac{1}{1000}$ ($99.9\%$ sure), $\epsilon = \frac{1}{10000}$ \\
$\implies M = \frac{3 \ln\left(\frac{2}{\frac{1}{1000}}\right) 4}{\pi \left(\frac{1}{10000}\right)^2} \approx 29106$. \\
Problems for MC (Monte-Carlo):
\begin{itemize}
  \item rare events, e.g. $X \sim \begin{pmatrix}0 & 10^{100} \\ 1-10^{-20} & 10^{-20}\end{pmatrix}, \; E(X) = 10^{80}$
    % skica
\end{itemize}


\section{DNF counting}

CNF: $(X_{i_1} \lor \overline{X_{i_2}} \lor X_{i_4}) \land (X_{i_1} \lor \overline{X_{i_3}}) \land \dots$ \\
DNF: $(\overline{X_{i_1}} \land X_{i_2} \lor \overline{X_{i_4}}) \lor \dots$
- easy to determine if solution exists. \\
Question: number of solutions to a given DNF? \\
Observation: CNF $F$ has a solution $\iff$ DNF $\neg F$ has less than $2^n$ solutions, $n$ is number of samples.
\begin{alltt}
  ALG_1(F):
    x = 0
    for i in range(1,m+1):
      \(x_1 \dots x_n\) uniformly random from \{0,1\}\(\sp{n}\)
      if \(F(x_1 \dots x_n)\) = 1:
        x += 1
    return \(\frac{x}{m} \cdot 2\sp{n}\)
\end{alltt}
$Y = \frac{\sum_{i=1}^{m} X_i}{m}$ \\
$(\epsilon,\delta)$-approximation for $Y$ \\
$E(Y) = \frac{\text{number of solutions of }F}{2^n} = \frac{c(F)}{2^n}$ \\
$m \geq \frac{3 \ln\left(\frac{2}{\delta}\right)}{\epsilon^2 E(X)} =
\frac{3 \ln\left(\frac{2}{\delta}\right)}{\epsilon^2} \cdot \frac{2^n}{x(F)}$ \\
$c(F)$ very small $\to$ $m$ exponentially big $\to$ not good (we need a lot of samples).
\begin{defn} \text{} \\
  $SC_i = \{(a_1 \dots a_n) \in \{0,1\}^n \text{ such that } F = F_1 \lor \dots \lor F_t, \; F_i(a_1 \dots a_n) = 1\}$.
  % skica
\end{defn}
$|SC_i| = 2^{n-l_i}$, $l_i$: number of values in $F_i$ \\
$U = \{(i,a) \mid i \in \{1,2 \dots t\}, a \in SC_i\}$ \\
$U = \sum_{i=1}^{t} |SC_i|$ - $O(tn)$ (space smaller than $\{0,1\}^n$) \\
$S = \{(i,a) \in U \mid a \in SC_i, \; a \not \in SC_j \; 1 \leq j < i\}$ \\
$|S| = |SC_1| + \dots + |SC_t| = c(F)$.
\begin{alltt}
  ALG_2(F):
    x = 0
    for i in range(1,m+1):
      (i, a) uniformly random from U (**)
      if (i, a) \(\in\) S: (*)
        x += 1
    return \(\frac{x}{m} \cdot |U|\)
\end{alltt}
$(*) \; a \in SC_i \to O(n), \; a \notin SC_j \; j = 1 \dots i-1 \to O(tn) \; \implies \; O(tn), m$ times. \\
$(**)$: watch for details on how to, e.g. $x_2, x_2 \land x_3$: $x_2$ is more probable than $x_2 \land x_3 \to O(1)$.
\begin{theorem}
  For $m = \lceil\frac{3t \ln(\left(\frac{2}{\delta}\right))}{\epsilon^2}\rceil$ algorithm returns $(\epsilon,\delta)$-approximation
  in $O\left(\frac{t^n n \ln\left(\frac{2}{\delta}\right)}{\epsilon^2}\right)$ time.
\end{theorem} 
\begin{pro}
  $O(t \cdot n \cdot m)$. \\
  Insert $m = ...$
\end{pro}
Prove
\begin{equation*}
  P_r(Y|U| - c(F) > \epsilon c(F)) < \delta:
\end{equation*}
$c(F) = |S|, E(Y) = \frac{|S|}{|U|}$
\begin{align*}
  P_r(Y|U| - c(F) > \epsilon c(F)) &= P_r(|U|(Y - E(Y)) > \epsilon |U| E(Y)) \leq \delta
\end{align*}
if
\begin{equation*}
  m \geq \frac{3 \ln\left(\frac{2}{\delta}\right)}{\epsilon^2 E(Y)} \geq \frac{3 \ln\left(\frac{2}{\delta}\right)t}{\epsilon^2}
\end{equation*}
where
\begin{equation*}
  E(Y) = \frac{|S|}{|U|} \geq \frac{1}{t}
\end{equation*}
($=$ if disjoint). \\
In new space $E(Y)$ much larger $\implies$ $m$ smaller.
% skica



\chapter{Polynomials}


Let $\F$ be a field. \\
$\F$ can be $\R, \C, \Z_p, \F_{p^n}$. \\
$\F[x_1 \dots x_n]$ algebra of polynomials with values $x_1 \dots x_n$. \\
$f \in \F[x_1 \dots x_n]$ \\
$deg(f[x_1 \dots x_n]) := deg(f[x \dots x])$.
\begin{theorem}
  Let $p(x_1 \dots x_n) \in \F[x_1 \dots x_n]$ have the degree $d \geq 0$ and $p \neq 0$.
  Let $s \subset \F$ be finite.
  If $(r_1 \dots r_n)$ is uniformly at random element from $S^n$.
  Then $P_r(p(r_1 \dots r_n) = 0) \leq \frac{d}{|S|}$.
\end{theorem}
\begin{pro}
  Induction on $n$. \\
  $n=1$:
  \begin{align*}
    &p(x) = (x-z_1) (x-z_2) \dots (x-z_j) q(z) \\
    &\text{number of zeros } \leq \text{ degree - fact} \\
    &P_r(p(r_1) = 0) = \frac{\text{number of zeros}}{|S|} \leq \frac{d}{|S|}.
  \end{align*}
  $n-1 \to n$:
  \begin{align*}
    &\text{rewrite }p: \\
    &p(x_1 \dots x_n) = \sum_{i=0}^{j} x^i p_i(x_2 \dots x_n) \\
    &j \leq d \\
    P_r(p(r_1 \dots r_n) = 0) &= P_r(p(r_1 \dots r_n = 0) \mid p_j(r_2 \dots r_n) = 0) \cdot P_r(p_j(r_2 \dots r_n) = 0) \\
    &+ P_r(p(r_1 \dots r_n = 0) \mid p_j(r_2 \dots r_n) \neq 0) \cdot P_r(p_j(r_2 \dots r_n) \neq 0) \\
    &\leq 1 \cdot \frac{d-j}{|S|} + \frac{j}{|S|} \cdot 1, \\
  \end{align*}
  because
  \begin{align*}
    &P_r(p(r_1 \dots r_n = 0) \mid p_j(r_2 \dots r_n) \neq 0) \leq \frac{d-j}{|S|} \\
    &P_r(p_j(r_2 \dots r_n) \neq 0) \leq \frac{j}{|S|}.
  \end{align*}
\end{pro}
\underline{Problem}: \\
Let $A,B,C \in \F^{n \times n}$, is $A \cdot B = C$? \\
Computing $A \cdot B$:
\begin{itemize}
  \item school-book algorithm: $O\left(n^3\right)$,
  \item Strassen algorithm: $O\left(n^{2,807\dots}\right)$,
  \item galactic algorithm: $O\left(n^{2.372\dots}\right)$ - has enormous constants.
\end{itemize}
\begin{alltt}
  RAND_ACB(A,B,C):
    for i in range(1,k+1):
      x uniformly at random from \{0,1\}\(\sp{n}\)
      if \(A \cdot (B \cdot x) \neq x\):
        return false
    return true
\end{alltt}
$O\left(k n^2\right)$.


%\clearpage
%\phantomsection

%\addcontentsline{toc}{chapter}{Literatura}
%\bibliography{../bibtex/literatura}
%\bibliographystyle{plainnat}


%\clearpage
%\phantomsection

%\chapter*{Dodatki}
%\addcontentsline{toc}{chapter}{Dodatki}
%D.




\end{document}
